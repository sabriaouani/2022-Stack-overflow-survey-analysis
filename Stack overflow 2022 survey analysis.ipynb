{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "0f4bb3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "b50b727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file in binary mode and detect the encoding type\n",
    "file_path = r'C:\\Users\\My PC\\Desktop\\future\\tableau\\stack over flow\\survey_results_public 2922.csv'\n",
    "with open(file_path, 'rb') as f:\n",
    "    result = chardet.detect(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "15068305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the excel file into a pandas DataFrame\n",
    "df = pd.read_csv(file_path, encoding=result['encoding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "afd96457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows where the 'ConvertedCompYearly' column is null\n",
    "df = df.dropna(subset=['ConvertedCompYearly'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "3fda1f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to keep only the rows with 'MainBranch' value 'I am a developer by profession'\n",
    "df = df[df['MainBranch'] == 'I am a developer by profession']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "58fa19d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the columns to drop\n",
    "columns_to_drop = ['CodingActivities', 'LearnCode', 'LearnCodeOnline', 'LearnCodeCoursesCert', 'YearsCodePro', \n",
    "                   'OrgSize', 'PurchaseInfluence', 'BuyNewTool', 'Currency', 'CompTotal', 'CompFreq', \n",
    "                   'LanguageWantToWorkWith', 'DatabaseWantToWorkWith', 'PlatformWantToWorkWith', \n",
    "                   'WebframeWantToWorkWith', 'MiscTechWantToWorkWith', 'ToolsTechWantToWorkWith', \n",
    "                   'NEWCollabToolsWantToWorkWith', 'OpSysPersonal use', 'VCHostingPersonal use', \n",
    "                   'VCHostingProfessional use', 'OfficeStackAsyncWantToWorkWith', 'OfficeStackSyncWantToWorkWith', \n",
    "                   'NEWSOSites', 'SOVisitFreq', 'SOVisitFreq', 'SOAccount', 'SOPartFreq', 'SOComm', \n",
    "                   'Trans', 'Sexuality', 'Ethnicity', 'Accessibility', 'MentalHealth', 'TBranch', 'ICorPM', \n",
    "                   'Knowledge_1', 'Knowledge_2', 'Knowledge_3', 'Knowledge_4', 'Knowledge_5', 'Knowledge_6', \n",
    "                   'Knowledge_7', 'Frequency_1', 'Frequency_2', 'Frequency_3', 'TimeSearching', 'TimeAnswering', \n",
    "                   'Onboarding', 'ProfessionalTech', 'TrueFalse_1', 'TrueFalse_2', 'TrueFalse_3', \n",
    "                   'SurveyLength', 'SurveyEase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "a503bfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns if they exist\n",
    "for col in columns_to_drop:\n",
    "    try:\n",
    "        df = df.drop(col, axis=1)\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "dee11f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace special characters with apostrophes\n",
    "df['EdLevel'] = df['EdLevel'].apply(lambda x: re.sub(r'[\\u2018\\u2019\\u201A\\u201B\\u2032\\u2035]+', \"'\", x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "e490b8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the \"ResponseId\" column if it exists\n",
    "if 'ResponseId' in df.columns:\n",
    "    df = df.drop('ResponseId', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "b1d53a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index to start from 0\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "6e7b7d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the \"index\" column to \"Id\" and add 1 to make it start from 1\n",
    "df.rename(columns={'index': 'Id'}, inplace=True)\n",
    "df['Id'] = df.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "2f70db7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated DataFrame back to a CSV file\n",
    "#df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "f17f3d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace non-\"Man\" and non-\"Woman\" values in the \"Gender\" column with \"Prefer not to say\"\n",
    "df.loc[~df['Gender'].isin(['Man', 'Woman']), 'Gender'] = 'Prefer not to say'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "189ebe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'ConvertedCompYearly': 'Salary'}, inplace=True)\n",
    "df.rename(columns={'LanguageHaveWorkedWith': 'language'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "e7c779d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with outlier numbers in the \"Salary\" column\n",
    "q1 = df['Salary'].quantile(0.25)\n",
    "q3 = df['Salary'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "upper_threshold = q3 + 1.5 * iqr\n",
    "df = df.loc[df['Salary'] <= upper_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "96ce25af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated DataFrame back to a CSV file\n",
    "#df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "cded148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the language column by ';'\n",
    "df['language'] = df['language'].str.split(';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "08933a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the language column to have one row per language\n",
    "df = df.explode('language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "5ce56637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a unique id to each language\n",
    "df['language_id'] = df.groupby('language').ngroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "cf95a56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the index\n",
    "#df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "ec18460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DatabaseHaveWorkedWith column by ';'\n",
    "df['DatabaseHaveWorkedWith'] = df['DatabaseHaveWorkedWith'].str.split(';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "44acbe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the DatabaseHaveWorkedWith column to have one row per DatabaseHaveWorkedWith\n",
    "df = df.explode('DatabaseHaveWorkedWith')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "ddc2f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a unique id to each DatabaseHaveWorkedWith\n",
    "df['DatabaseHaveWorkedWith_id'] = df.groupby('DatabaseHaveWorkedWith').ngroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "27d8ab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the OfficeStackAsyncHaveWorkedWith column by ';'\n",
    "df['OfficeStackAsyncHaveWorkedWith'] = df['OfficeStackAsyncHaveWorkedWith'].str.split(';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "f31ae50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the DatabaseHaveWorkedWith column to have one row per DatabaseHaveWorkedWith\n",
    "df = df.explode('OfficeStackAsyncHaveWorkedWith')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "c757d509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a unique id to each DatabaseHaveWorkedWith\n",
    "df['OfficeStackAsyncHaveWorkedWith_id'] = df.groupby('OfficeStackAsyncHaveWorkedWith').ngroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "79f22468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the OfficeStackSyncHaveWorkedWith column by ';'\n",
    "df['OfficeStackSyncHaveWorkedWith'] = df['OfficeStackSyncHaveWorkedWith'].str.split(';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "dd629e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the OfficeStackSyncHaveWorkedWith column to have one row per OfficeStackSyncHaveWorkedWith\n",
    "df = df.explode('OfficeStackSyncHaveWorkedWith')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "5117fa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a unique id to each OfficeStackSyncHaveWorkedWith\n",
    "df['OfficeStackSyncHaveWorkedWith_id'] = df.groupby('OfficeStackSyncHaveWorkedWith').ngroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "9b1f84ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the PlatformHaveWorkedWith column by ';'\n",
    "#df['PlatformHaveWorkedWith'] = df['PlatformHaveWorkedWith'].str.split(';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "9fe41373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the PlatformHaveWorkedWith column to have one row per PlatformHaveWorkedWith\n",
    "#df = df.explode('PlatformHaveWorkedWith')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "a24ccd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a unique id to each PlatformHaveWorkedWith\n",
    "#df['PlatformHaveWorkedWith_id'] = df.groupby('PlatformHaveWorkedWith').ngroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "95e146ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "dfb464a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the values in the DevType column and replace null values with a default value\n",
    "df['DevType'] = df['DevType'].str.split(';').str[0].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "2e065943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Salary column to numeric type and replace NaN values with 0\n",
    "df['Salary'] = pd.to_numeric(df['Salary'], errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "43fb4733",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WorkExp'] = pd.to_numeric(df['WorkExp'], errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "a3f7df72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_yearscode_to_int(yearscode_str):\n",
    "    if yearscode_str is None:\n",
    "        return None\n",
    "    elif yearscode_str == 'Less than 1 year':\n",
    "        return 0\n",
    "    elif yearscode_str == 'More than 50 years':\n",
    "        return 55\n",
    "    else:\n",
    "        return yearscode_str\n",
    "\n",
    "df['YearsCode'] = df['YearsCode'].apply(map_yearscode_to_int)\n",
    "df['YearsCode'] = df['YearsCode'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ed760e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "3aab02c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract the age from an age range string\n",
    "def extract_age_from_range(age_str):\n",
    "    if not isinstance(age_str, str):\n",
    "        return None\n",
    "    elif age_str in ['Prefer not to say', None]:\n",
    "        return None\n",
    "    elif age_str == '65 years or older':\n",
    "        return 65\n",
    "    elif age_str == 'Under 18 years old':\n",
    "        return 17\n",
    "    else:\n",
    "        age_range = age_str.split('-')\n",
    "        age_min = int(age_range[0])\n",
    "        age_max = int(age_range[1].split()[0])\n",
    "        return (age_min + age_max) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "afe857a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Exact age'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3628\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3629\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Exact age'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28988\\3637966066.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Apply the function to the \"Age\" column to extract the age from each age range\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Exact age'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Exact age'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3504\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3505\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3506\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3507\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3629\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3631\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3632\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3633\u001b[0m                 \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Exact age'"
     ]
    }
   ],
   "source": [
    "# Apply the function to the \"Age\" column to extract the age from each age range\n",
    "df['Exact age'] = df['Exact age'].apply(lambda x: math.floor(x) if not math.isnan(x) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fdd708",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WorkExp'] = pd.to_numeric(df['Exact age'], errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a32238",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dev_types = df['Exact age'].unique()\n",
    "unique_dev_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182fe62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1059ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fuck israel\n",
    "df = df[df['Country'] != 'Israel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4a062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['MainBranch', 'Blockchain'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7b556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated DataFrame back to a CSV file\n",
    "df.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
